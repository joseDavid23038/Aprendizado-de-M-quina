{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validação cruzada\n",
    "=================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No notebook 5.1 nós vimos que avaliar a performance de modelos utilizando os dados usados para treinar os modelos nos fornece uma métrica de performance que é *superestimada* (isto é, a performance do modelo aparenta ser melhor do que realmente é).\n",
    "\n",
    "A solução para buscar uma melhor forma de avaliar a performance dos modelos foi a separação dos dados em um conjunto de treino e um conjunto de teste.\n",
    "\n",
    "Aqui neste notebook veremos uma estratégia para *seleção de modelos*. Seleção de modelos é diferente de avaliação de modelos. Isto vai ficar claro ao longo deste notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados necessários\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de seguir em frente, precisamos de dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "DATASET_NAME = \"penguins\"\n",
    "FEATURES = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\n",
    "TARGET = [\"body_mass_g\"]\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "\n",
    "df = df.reindex(FEATURES + TARGET, axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "X = df.reindex(FEATURES, axis=1).values\n",
    "y = df.reindex(TARGET, axis=1).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O acaso vai me proteger&#x2026; se eu não forçar a barra\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código abaixo, nós estamos treinando uma árvore de decisão nos dados dos pinguins que carregamos na seção anterior. Observe o que acontece com a performance do modelo quando variamos a semente aleatória (observe que a performance está sendo medida da maneira correta, isto é, no conjunto de teste).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "N = 5000\n",
    "\n",
    "resultado = []\n",
    "\n",
    "for semente in range(N):\n",
    "    modelo_dt = DecisionTreeRegressor(random_state=semente)\n",
    "\n",
    "    modelo_dt.fit(X_treino, y_treino)\n",
    "\n",
    "    y_verdadeiro = y_teste\n",
    "    y_previsao = modelo_dt.predict(X_teste)\n",
    "    RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "    resultado.append(RMSE)\n",
    "\n",
    "figura, eixo = plt.subplots()\n",
    "eixo.hist(resultado)\n",
    "eixo.set_xlabel(\"RMSE\")\n",
    "eixo.set_ylabel(\"Quantidade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afinal de contas, qual é a performance deste modelo? Porque variando a semente aleatória a performance varia?\n",
    "\n",
    "Este experimento que realizamos acima nos mostra que mesmo pequenas variações nas árvores de decisão induzidas pelo modelo resultam em alterações na performance. Estas variações no modelo ocorrem pois alteramos a semente aleatória, releia o notebook 5.2 para relembrar que induzir uma árvore de decisão é um problema NP-difícil e que o `scikit-learn` usa um algoritmo que não necessariamente entrega a melhor resposta.\n",
    "\n",
    "Por puro acaso, variações no modelo podem prever melhor ou pior os dados de treino, e é por isso que vemos uma distribuição nos valores de performance neste experimento.\n",
    "\n",
    "Geralmente, não nos preocupamos com o acaso quando treinamos modelos pois esperamos que o efeito do acaso seja pequeno (isto é, assumimos que a nossa avaliação da performance no conjunto de teste é uma estimativa razoável). No entanto, quando &ldquo;forçamos a barra&rdquo; podemos observar situações inusitadas por puro efeito do acaso, como foi o caso do experimento que realizamos acima.\n",
    "\n",
    "Quando reusamos o mesmo conjunto de teste para diversos modelos diferentes, aumentamos a chance de observar modelos com estimativas de performance muito discrepantes (para mais ou para menos) por pura ação do acaso. Um artigo que discute de forma excelente isso é a referência [1].\n",
    "\n",
    "O nome técnico deste conceito é &ldquo;vazamento de dados&rdquo; ou *data leakage* em inglês (ver referência [2]). Quando usamos o mesmo conjunto de teste várias vezes, dizemos que a informação dos dados de teste &ldquo;vazaram&rdquo; para o treino (efeito do acaso discutido acima). Outra forma de ocorrer vazamento de dados é quando existem dados duplicados no seu conjunto de dados (isto é, dados com mesmos valores de atributos); desta forma você corre o risco de dados &ldquo;iguais&rdquo; a dados do conjunto de treino cairem no conjunto de teste durante seu split, o que faz com que seu modelo seja treinado com informações que deveriam ser novas (os dados de teste deveriam ser novidade para seu modelo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação de modelos com validação cruzada $k$​-fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma estratégia para reduzir o efeito do acaso para avaliar um modelo induzido por aprendizado de máquina é o processo de *validação cruzada* (cross-validation em inglês).\n",
    "\n",
    "A validação cruzada mais usada é a chamada de $k$​-fold, representada na imagem abaixo. Nesta estratégia, nós dividimos o conjunto de dados em $k$ subconjuntos diferentes de mesmo tamanho (ou o mais próximo possível disso). Em cada iteração da validação cruzada, um destes subconjuntos é designado como conjunto de teste e os demais como conjunto de treino de forma que todo subconjunto seja teste uma vez.\n",
    "\n",
    "Nesta estratégia, nós treinamos $k$ modelos e temos $k$ estimativas da performance. A média das $k$ estimativas de performance é o valor que usaremos para avaliar o modelo sendo estudado.\n",
    "\n",
    "![img](https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg)\n",
    "\n",
    "Observe que a estratégia de validação cruzada é menos susceptível ao acaso do que a estratégia de split em treino e teste que vimos anteriormente.\n",
    "\n",
    "A escolha do valor de $k$ é um ponto muito importante. Quanto maior o valor de $k$ maior o custo computacional do processo de validação cruzada. Quanto menor o valor de $k$ pior será sua estimativa da performance. Em geral, um valor de $k=10$ costuma ser muito bom, mas $k=5$ também é considerado bom e menos custoso.\n",
    "\n",
    "Vamos ver como fazer uma validação cruzada no `scikit-learn`. Note que aqui não fizemos o split de treino e teste pois quem está cuidando disso é a própria função `cross_val_score`. Outro detalhe é que a função `cross_val_score` pode receber o argumento `scoring` que é a medida da performance que temos interesse. Aqui queremos a métrica RMSE e por isso passamos o valor `neg_root_mean_squared_error`. Existem diversos scores possíveis que podemos utilizar para a validação cruzada. Você pode checar as que já estão embutidas no `scikit-learn` na [documentação](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As métricas foram:  [-560.08609032 -496.21783811 -495.60569004 -501.65168371 -437.19527203\n",
      " -562.23032751 -515.70910633 -456.58982107 -364.25790798 -525.29753474]\n",
      "\n",
      "A média das métricas é de:  -491.48412718394883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "modelo_dt = DecisionTreeRegressor()\n",
    "\n",
    "metricas = cross_val_score(\n",
    "    modelo_dt,\n",
    "    X,\n",
    "    y,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "\n",
    "print(\"As métricas foram: \", metricas)\n",
    "print()\n",
    "print(\"A média das métricas é de: \", metricas.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ué, como assim o RMSE deu negativo? Isso acontece porque o `scikit-learn` definiu que métricas com o nome de *score* devem todas seguir a mesma regra: quanto maior, melhor! No entanto, sabemos que quanto menor o RMSE melhor a performance do meu modelo. Para satisfazer a definição de score do `scikit-learn`, devemos usar o negativo do RMSE como score (por isso tem um `neg` na string que passamos no argumento `scoring`, vem de &ldquo;negativo&rdquo;). Basta você remover o sinal de negativo e terá seu RMSE tradicional como de costume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A média das métricas é de:  491.48412718394883\n"
     ]
    }
   ],
   "source": [
    "print(\"A média das métricas é de: \", abs(metricas.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Avaliar* a performance de modelos é muito importante. No entanto, muitas vezes nós temos interesse em realizar o passo seguinte que é o de *selecionar* modelos. Pode parecer que são processos iguais mas não são!\n",
    "\n",
    "Seleção de modelos é escolher um bom conjunto de hiperparâmetros para um certo algoritmo de aprendizado de máquina. Este processo também é conhecido como *otimização de hiperparâmetros* ou *hyperparameter tuning* ou simplesmente *hp tuning*.\n",
    "\n",
    "Este processo envolve os conceitos de split treino-teste com a validação cruzada. Os passos são os seguintes:\n",
    "\n",
    "1.  Dividir o conjunto de dados em treino e teste;\n",
    "\n",
    "2.  Realizar validação cruzada considerando apenas o conjunto de treino. Registrar a performance de cada conjunto de hiperparâmetros testados. Escolher o conjunto de hiperparâmetros que resultou na melhor performance;\n",
    "\n",
    "3.  Treinar um modelo usando os hiperparâmetros encontrados no passo 2 em *todos* os dados de treino;\n",
    "\n",
    "4.  Avaliar a performance do modelo obtido no passo 3 no conjunto de teste obtido no passo 1.\n",
    "\n",
    "Uma representação visual pode ser conferida na imagem abaixo. A figura 16 da referência [1] mostra os passos discutidos acima.\n",
    "\n",
    "![img](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros com `scikit-learn` (busca em grade)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problemas de otimização* são problemas onde buscamos maximizar ou minimizar uma função objetivo. O problema de otimização de hiperparâmetros é um tipo de problema de otimização.\n",
    "\n",
    "Uma estratégia para resolver problemas de otimização é definir todos os valores possíveis dos parâmetros que estamos estudando (neste caso são os hiperparâmetros dos modelos) e estudar os resultados de todas as possíveis combinações entre eles. Esta é a estratégia chamada de *busca em grade*.\n",
    "\n",
    "Podemos realizar esta busca usando o `scikit-learn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "240 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [          nan -497.81207032 -477.79091143 -478.65185422           nan\n",
      " -462.65529061 -458.19957645 -459.06408072           nan -421.93003632\n",
      " -421.52211392 -431.31326048           nan -412.18360319 -411.24070482\n",
      " -408.95868991           nan -424.50214947 -424.50214947 -424.50214947\n",
      "           nan -424.50214947 -424.50214947 -424.50214947           nan\n",
      " -424.50214947 -424.50214947 -424.50214947           nan -424.50214947\n",
      " -424.50214947 -424.50214947           nan -398.49217574 -398.49217574\n",
      " -398.49217574           nan -398.49217574 -398.49217574 -398.49217574\n",
      "           nan -398.49217574 -398.49217574 -398.49217574           nan\n",
      " -398.49217574 -398.49217574 -398.49217574           nan -412.16208972\n",
      " -409.93182812 -411.86194168           nan -407.30444522 -410.29581047\n",
      " -407.58195631           nan -405.21246023 -407.84944685 -407.84944685\n",
      "           nan -404.36973761 -407.07326721 -404.36973761           nan\n",
      " -455.5728254  -447.62448145 -446.43670417           nan -437.55603588\n",
      " -435.85308673 -428.28438238           nan -411.00847042 -410.45540173\n",
      " -418.26282036           nan -412.91275817 -409.75065311 -410.24016356\n",
      "           nan -497.5481258  -489.07801022 -469.61410427           nan\n",
      " -448.82402594 -457.89291294 -456.32163913           nan -423.12053918\n",
      " -423.20609543 -422.33379609           nan -412.29864748 -409.47963402\n",
      " -409.47963402]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-497.812070</td>\n",
       "      <td>71.011870</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-477.790911</td>\n",
       "      <td>71.198823</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-478.651854</td>\n",
       "      <td>64.315350</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 2, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-422.333796</td>\n",
       "      <td>48.798450</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 3, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-412.298647</td>\n",
       "      <td>50.635260</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-409.479634</td>\n",
       "      <td>49.755455</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-409.479634</td>\n",
       "      <td>49.755455</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 4, 'min_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0               NaN             NaN   \n",
       "1       -497.812070       71.011870   \n",
       "2       -477.790911       71.198823   \n",
       "3       -478.651854       64.315350   \n",
       "4               NaN             NaN   \n",
       "..              ...             ...   \n",
       "91      -422.333796       48.798450   \n",
       "92              NaN             NaN   \n",
       "93      -412.298647       50.635260   \n",
       "94      -409.479634       49.755455   \n",
       "95      -409.479634       49.755455   \n",
       "\n",
       "                                               params  \n",
       "0   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
       "1   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
       "2   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
       "3   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
       "4   {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
       "..                                                ...  \n",
       "91  {'max_depth': 10, 'min_samples_leaf': 3, 'min_...  \n",
       "92  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "93  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "94  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "95  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "espaco_de_busca = {\n",
    "    \"max_depth\": [None, 2, 3, 5, 7, 10],\n",
    "    \"min_samples_split\": [1, 2, 3, 4],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "modelo_dt = DecisionTreeRegressor()\n",
    "\n",
    "buscador = GridSearchCV(\n",
    "    modelo_dt,\n",
    "    espaco_de_busca,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    refit=True,  # reajusta o melhor modelo com todos os dados de treino\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "buscador.fit(X_treino, y_treino)\n",
    "\n",
    "resultados = pd.DataFrame(buscador.cv_results_)\n",
    "resultados = resultados.reindex(\n",
    "[\"mean_test_score\", \"std_test_score\", \"params\"], axis=1)\n",
    "display(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver o resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor métrica (considerando dados de treino) foi de  398.49217574308653\n",
      "O conjunto de hiperparâmetros que resultou nesta métrica foi  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"A melhor métrica (considerando dados de treino) foi de \", abs(buscador.best_score_))\n",
    "print(\"O conjunto de hiperparâmetros que resultou nesta métrica foi \", buscador.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos estimar a performance deste modelo para dados que nunca viu!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo escolhido foi de 398.25285598626624 unidades de y.\n"
     ]
    }
   ],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = buscador.predict(X_teste)\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "print(f\"O RMSE do modelo escolhido foi de {RMSE} unidades de y.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros com `scikit-learn` (busca aleatória)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A busca em grade que vimos na seção anterior irá testar todas as combinações possíveis dentro do espaço de busca. Isso pode ser muito custoso se o espaço de busca for muito grande! Para resolver este problema, podemos usar a *busca aleatória* que, como o próprio nome sugere, irá combinar os hiperparâmetros do espaço de busca de forma aleatória em busca de um bom conjunto de hiperparâmetros.\n",
    "\n",
    "Esta estratégia costuma ser menos custosa, mas em contrapartida não temos garantia de que o melhor conjunto de hiperparâmetros será sorteado durante a busca.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "270 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jose23038\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-401.64817606 -528.73044721 -403.26457736           nan           nan\n",
      " -536.0819389  -524.05746975 -407.32872354           nan -445.41452403\n",
      " -529.14787454           nan -398.49217574 -429.52080114           nan\n",
      " -434.22752691 -433.25386893 -430.3808971  -400.92516715           nan\n",
      " -495.23817221 -431.15296194 -476.63609841 -398.49217574           nan\n",
      " -424.50214947           nan -409.95154188 -459.11199742 -407.24656808\n",
      " -508.28225302 -474.69950334 -505.24470231           nan -453.98500812\n",
      " -407.94567116 -411.77304027           nan -456.71339918 -430.48088749\n",
      " -502.38276167 -464.1514426  -449.69350278 -497.21430289           nan\n",
      "           nan -416.12757015 -411.00340555 -452.76658214 -518.64064337\n",
      " -400.22539142 -394.14129278 -499.88177172 -455.66531766 -417.23144131\n",
      " -389.47791072 -460.98123061 -470.64983216 -424.50214947           nan\n",
      " -459.76850198 -412.91593272           nan -402.55400563 -470.71847588\n",
      " -460.26701502 -533.46243512 -443.1908944            nan -413.73793722\n",
      "           nan -438.57256388           nan -398.49217574           nan\n",
      "           nan -398.76715077 -404.36973761           nan -465.36927417\n",
      " -425.11316677 -436.08471578 -498.71334319 -483.60800754 -467.68093364\n",
      " -510.72834088 -394.97845711 -490.00809273           nan -460.0848053\n",
      "           nan -401.17793783           nan -426.16802211 -452.40165504\n",
      "           nan           nan -395.31608286           nan           nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-401.648176</td>\n",
       "      <td>75.536094</td>\n",
       "      <td>{'min_samples_split': 4, 'min_samples_leaf': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-528.730447</td>\n",
       "      <td>109.257151</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-403.264577</td>\n",
       "      <td>52.062017</td>\n",
       "      <td>{'min_samples_split': 4, 'min_samples_leaf': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-395.316083</td>\n",
       "      <td>73.112925</td>\n",
       "      <td>{'min_samples_split': 2, 'min_samples_leaf': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'min_samples_split': 1, 'min_samples_leaf': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0       -401.648176       75.536094   \n",
       "1       -528.730447      109.257151   \n",
       "2       -403.264577       52.062017   \n",
       "3               NaN             NaN   \n",
       "4               NaN             NaN   \n",
       "..              ...             ...   \n",
       "95              NaN             NaN   \n",
       "96              NaN             NaN   \n",
       "97      -395.316083       73.112925   \n",
       "98              NaN             NaN   \n",
       "99              NaN             NaN   \n",
       "\n",
       "                                               params  \n",
       "0   {'min_samples_split': 4, 'min_samples_leaf': 3...  \n",
       "1   {'min_samples_split': 2, 'min_samples_leaf': 1...  \n",
       "2   {'min_samples_split': 4, 'min_samples_leaf': 1...  \n",
       "3   {'min_samples_split': 1, 'min_samples_leaf': 3...  \n",
       "4   {'min_samples_split': 1, 'min_samples_leaf': 1...  \n",
       "..                                                ...  \n",
       "95  {'min_samples_split': 1, 'min_samples_leaf': 4...  \n",
       "96  {'min_samples_split': 1, 'min_samples_leaf': 3...  \n",
       "97  {'min_samples_split': 2, 'min_samples_leaf': 3...  \n",
       "98  {'min_samples_split': 1, 'min_samples_leaf': 2...  \n",
       "99  {'min_samples_split': 1, 'min_samples_leaf': 1...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "NUM_ITERACOES = 100\n",
    "\n",
    "espaco_de_busca = {\n",
    "    \"max_depth\": [None, 2, 3, 5, 7, 10],\n",
    "    \"min_samples_split\": [1, 2, 3, 4],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4],\n",
    "    \"max_features\": [None, 0.33, \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "modelo_dt = DecisionTreeRegressor()\n",
    "\n",
    "buscador = RandomizedSearchCV(\n",
    "    modelo_dt,\n",
    "    espaco_de_busca,\n",
    "    n_iter=NUM_ITERACOES,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    refit=True,  # reajusta o melhor modelo com todos os dados de treino\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "buscador.fit(X_treino, y_treino)\n",
    "\n",
    "resultados = pd.DataFrame(buscador.cv_results_)\n",
    "resultados = resultados.reindex(\n",
    "    [\"mean_test_score\", \"std_test_score\", \"params\"], axis=1 )\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver o resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor métrica (considerando dados de treino) foi de  377.1039500260672\n",
      "O conjunto de hiperparâmetros que resultou nesta métrica foi  {'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"A melhor métrica (considerando dados de treino) foi de \", abs(buscador.best_score_))\n",
    "print(\"O conjunto de hiperparâmetros que resultou nesta métrica foi \", buscador.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos estimar a performance deste modelo para dados que nunca viu!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo escolhido foi de 576.2012060945017 unidades de y.\n"
     ]
    }
   ],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = buscador.predict(X_teste)\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "print(f\"O RMSE do modelo escolhido foi de {RMSE} unidades de y.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que fazer quando se tem um grande conjunto de dados?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando temos um *grande* conjunto de dados, a validação cruzada pode ser custosa demais de ser realizada. Neste caso, podemos realizar o *método da separação em 3 partes* (3-way holdout method em inglês), também conhecido como *split de treino-teste-validação*. Os passos são os seguintes:\n",
    "\n",
    "1.  Dividir o conjunto de dados em treino, teste e validação (uma divisão usual é 80-10-10);\n",
    "\n",
    "2.  Treinar modelos com diferentes hiperparâmetros apenas no conjunto de treino. Escolher o conjunto de hiperparâmetros que apresentar melhor performance na previsão do conjunto de validação.\n",
    "\n",
    "3.  Treinar um modelo usando os hiperparâmetros encontrados no passo 2 considerando todos os dados de treino e validação;\n",
    "\n",
    "4.  Avaliar a performance do modelo obtido no passo 3 no conjunto de teste obtido no passo 1.\n",
    "\n",
    "Para mais informações ver a seção 3.3 da referência [1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  RASCHKA, Sebastian. Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning. 2020. Disponível em: [http://arxiv.org/abs/1811.12808](http://arxiv.org/abs/1811.12808). Acesso em: 2 jul. 2023.\n",
    "\n",
    "2.  KAUFMAN, Shachar; ROSSET, Saharon; PERLICH, Claudia; et al. Leakage in data mining: Formulation, detection, and avoidance. ACM Transactions on Knowledge Discovery from Data, v. 6, n. 4, p. 15:1-15:21, 2012.\n",
    "\n",
    "3.  Guia sobre validação cruzada do `scikit-learn` [https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "4.  Tutorial sobre validação cruzada [https://dev.to/balapriya/cross-validation-and-hyperparameter-search-in-scikit-learn-a-complete-guide-5ed8](https://dev.to/balapriya/cross-validation-and-hyperparameter-search-in-scikit-learn-a-complete-guide-5ed8)\n",
    "\n",
    "5.  Documentação da validação cruzada com busca em grade [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "6.  Documentação da validação cruzada com busca aleatória [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "org": null,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
